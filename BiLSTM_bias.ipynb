{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8076,
          "databundleVersionId": 44219,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30636,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense,Dropout,Input,Embedding,Flatten,TextVectorization,Conv1D,GlobalMaxPooling1D,MaxPooling1D,GlobalAveragePooling1D\n",
        "from keras.initializers import Constant\n",
        "from keras.layers import Dense,LSTM,Bidirectional,Attention,Concatenate,GRU,BatchNormalization\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import jieba\n",
        "import random"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:24:00.384183Z",
          "iopub.execute_input": "2024-01-27T12:24:00.384762Z",
          "iopub.status.idle": "2024-01-27T12:24:12.465997Z",
          "shell.execute_reply.started": "2024-01-27T12:24:00.384709Z",
          "shell.execute_reply": "2024-01-27T12:24:12.465028Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkfroFOcPYkQ",
        "outputId": "5a6d82f8-8db4-4a4a-c38c-5a814b818dd8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_pairs = pd.read_csv('drive/MyDrive/train_pairsS2S.csv')\n",
        "valid_pairs = pd.read_csv('drive/MyDrive/valid_pairsS2S.csv')\n",
        "test_pairs = pd.read_csv('drive/MyDrive/test_pairsS2S.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:24:18.712267Z",
          "iopub.execute_input": "2024-01-27T12:24:18.712607Z",
          "iopub.status.idle": "2024-01-27T12:24:19.707068Z",
          "shell.execute_reply.started": "2024-01-27T12:24:18.712578Z",
          "shell.execute_reply": "2024-01-27T12:24:19.706107Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMlYQ6CWPYkQ",
        "outputId": "4838d176-44b1-4527-f318-86f17dafb63a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BiLSTM with random choice of biased or unbiased sentence per pair"
      ],
      "metadata": {
        "id": "K7N7AdPmnjX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store labeled data\n",
        "labeled_train = []\n",
        "\n",
        "# Iterate through each tuple in 'data'\n",
        "for row in train_pairs.text_pairs_dict:\n",
        "    # Randomly select either src_raw or tgt_raw\n",
        "    row = eval(row)\n",
        "    text = random.choice(row)\n",
        "\n",
        "    # Determine the label based on whether the selected text is from src_raw or tgt_raw\n",
        "    label = 0 if text == row[0] else 1\n",
        "\n",
        "    # Append the tuple containing the selected text and its label to 'labeled_data'\n",
        "    labeled_train.append((text, label))\n",
        "\n",
        "# Shuffle the labeled_data\n",
        "random.shuffle(labeled_train)\n",
        "\n",
        "# Separate the data into two lists based on labels\n",
        "label_0_train = [(text, label) for text, label in labeled_train if label == 0]\n",
        "label_1_train = [(text, label) for text, label in labeled_train if label == 1]\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "data_train = label_0_train + label_1_train\n",
        "df_train = pd.DataFrame(data_train, columns=['text', 'label'])\n",
        "y_train = df_train['label']\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"Train Data:\")\n",
        "print(df_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjM2-Xq1qRd9",
        "outputId": "3cd848da-850e-45d1-8a85-e8ca181f413b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data:\n",
            "                                                text  label\n",
            "0  city hall of buffalo, new york, an art-deco ma...      0\n",
            "1  the hospital stands on the site of the former ...      0\n",
            "2  at judgment day 2004, jbl defeated the late gr...      0\n",
            "3  several new academic and residence buildings h...      0\n",
            "4  the president of niger was overthrown in febru...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store labeled data\n",
        "labeled_val = []\n",
        "\n",
        "# Iterate through each tuple in 'data'\n",
        "for row in valid_pairs.text_pairs_dict:\n",
        "    # Randomly select either src_raw or tgt_raw\n",
        "    row = eval(row)\n",
        "    text = random.choice(row)\n",
        "\n",
        "    # Determine the label based on whether the selected text is from src_raw or tgt_raw\n",
        "    label = 0 if text == row[0] else 1\n",
        "\n",
        "    # Append the tuple containing the selected text and its label to 'labeled_data'\n",
        "    labeled_val.append((text, label))\n",
        "\n",
        "# Shuffle the labeled_data\n",
        "random.shuffle(labeled_val)\n",
        "\n",
        "# Separate the data into two lists based on labels\n",
        "label_0_val = [(text, label) for text, label in labeled_val if label == 0]\n",
        "label_1_val = [(text, label) for text, label in labeled_val if label == 1]\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "data_val = label_0_val + label_1_val\n",
        "df_val = pd.DataFrame(data_val, columns=['text', 'label'])\n",
        "y_val = df_val['label']\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"Train Data:\")\n",
        "print(df_val.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrgjHU85qqYX",
        "outputId": "e5c06017-ef6a-43f6-a24a-54523b59720d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data:\n",
            "                                                text  label\n",
            "0  the film was simultaneously screened and webca...      0\n",
            "1  the internationale (l'internationale in french...      0\n",
            "2  ironically, ferguson was created to relieve ov...      0\n",
            "3  southern mindanao has been terrorized by the r...      0\n",
            "4  nephilim (or giants) are offspring of supernat...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store labeled data\n",
        "labeled_test = []\n",
        "\n",
        "# Iterate through each tuple in 'data'\n",
        "for row in test_pairs.text_pairs_dict:\n",
        "    # Randomly select either src_raw or tgt_raw\n",
        "    row = eval(row)\n",
        "    text = random.choice(row)\n",
        "\n",
        "    # Determine the label based on whether the selected text is from src_raw or tgt_raw\n",
        "    label = 0 if text == row[0] else 1\n",
        "\n",
        "    # Append the tuple containing the selected text and its label to 'labeled_data'\n",
        "    labeled_test.append((text, label))\n",
        "\n",
        "# Shuffle the labeled_data\n",
        "random.shuffle(labeled_test)\n",
        "\n",
        "# Separate the data into two lists based on labels\n",
        "label_0_test = [(text, label) for text, label in labeled_test if label == 0]\n",
        "label_1_test = [(text, label) for text, label in labeled_test if label == 1]\n",
        "\n",
        "\n",
        "# Convert to DataFrame\n",
        "data_test = label_0_test + label_1_test\n",
        "df_test = pd.DataFrame(data_test, columns=['text', 'label'])\n",
        "y_test = df_test['label']\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"\\nTest Data:\")\n",
        "print(df_test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysPN4pMSrN4G",
        "outputId": "fde2eab8-b8c0-4413-fa5d-5371c242d517"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Data:\n",
            "                                                text  label\n",
            "0  by its terms the proposed withdrawal agreement...      0\n",
            "1  a football coach with years of successful expe...      0\n",
            "2  the novel's scope takes in aspects of establis...      0\n",
            "3  mr. rice's illustrious scouting career spanned...      0\n",
            "4  hisham selim (arabic: ) is a famous egyptian a...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(data_train)} training sentences\")\n",
        "print(f\"{len(data_val)} training sentences\")\n",
        "print(f\"{len(data_test)} test sentences\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX3BojoPmpD7",
        "outputId": "d1cf9113-4cb3-490b-bace-a0d675288020"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127033 training sentences\n",
            "27220 training sentences\n",
            "27220 test sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove common English stop words\n",
        "def clean(text):\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tokens = [word for word in text.split() if word not in stop_words]\n",
        "  text = ' '.join(tokens)\n",
        "  return text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:24:26.097298Z",
          "iopub.execute_input": "2024-01-27T12:24:26.097844Z",
          "iopub.status.idle": "2024-01-27T12:24:26.105185Z",
          "shell.execute_reply.started": "2024-01-27T12:24:26.097813Z",
          "shell.execute_reply": "2024-01-27T12:24:26.10443Z"
        },
        "trusted": true,
        "id": "imMXmTz6PYkR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_cleaned = df_train['text'].apply(clean)\n",
        "x_val_cleaned = df_val['text'].apply(clean)\n",
        "x_test_cleaned = df_test['text'].apply(clean)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:24:26.106223Z",
          "iopub.execute_input": "2024-01-27T12:24:26.106477Z",
          "iopub.status.idle": "2024-01-27T12:25:11.476629Z",
          "shell.execute_reply.started": "2024-01-27T12:24:26.106455Z",
          "shell.execute_reply": "2024-01-27T12:25:11.475778Z"
        },
        "trusted": true,
        "id": "rVJR7Dc3PYkS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train_cleaned)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(x_train_cleaned)\n",
        "X_val_sequences = tokenizer.texts_to_sequences(x_val_cleaned)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(x_test_cleaned)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:25:11.477803Z",
          "iopub.execute_input": "2024-01-27T12:25:11.478088Z",
          "iopub.status.idle": "2024-01-27T12:25:30.761733Z",
          "shell.execute_reply.started": "2024-01-27T12:25:11.478064Z",
          "shell.execute_reply": "2024-01-27T12:25:30.760882Z"
        },
        "trusted": true,
        "id": "r1J2vNCAPYkS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index)\n",
        "print(total_words) #same as length of vocabulary"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:25:30.763085Z",
          "iopub.execute_input": "2024-01-27T12:25:30.763414Z",
          "iopub.status.idle": "2024-01-27T12:25:30.768322Z",
          "shell.execute_reply.started": "2024-01-27T12:25:30.763388Z",
          "shell.execute_reply": "2024-01-27T12:25:30.767448Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S38uUNsePYkS",
        "outputId": "173596e5-22b8-4b35-b022-8aff529c4fad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "134081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_len=len(tokenizer.index_word)+1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:25:30.769521Z",
          "iopub.execute_input": "2024-01-27T12:25:30.769799Z",
          "iopub.status.idle": "2024-01-27T12:25:30.778753Z",
          "shell.execute_reply.started": "2024-01-27T12:25:30.769776Z",
          "shell.execute_reply": "2024-01-27T12:25:30.777963Z"
        },
        "trusted": true,
        "id": "NEqAOKmGPYkS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the length of the maximum sequence in the dataset\n",
        "max_length = max([len(w) for w in X_train_sequences])\n",
        "print(max_length)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:35:52.911812Z",
          "iopub.execute_input": "2024-01-27T12:35:52.912686Z",
          "iopub.status.idle": "2024-01-27T12:35:52.937701Z",
          "shell.execute_reply.started": "2024-01-27T12:35:52.912651Z",
          "shell.execute_reply": "2024-01-27T12:35:52.936777Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7m_xZ6nMPYkS",
        "outputId": "84257a6a-685a-4f8c-fba5-40427326e58a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding the sequences\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=200, padding='post', truncating='post')\n",
        "X_val_padded = pad_sequences(X_val_sequences, maxlen=200, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=200, padding='post', truncating='post')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:25:30.779738Z",
          "iopub.execute_input": "2024-01-27T12:25:30.780026Z",
          "iopub.status.idle": "2024-01-27T12:25:32.522994Z",
          "shell.execute_reply.started": "2024-01-27T12:25:30.78Z",
          "shell.execute_reply": "2024-01-27T12:25:32.521967Z"
        },
        "trusted": true,
        "id": "LtHv7QTtPYkS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input layer\n",
        "input_layer = Input(shape=(200,))  # Specify max_len as the maximum sequence length\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(emb_len, 128)(input_layer)\n",
        "\n",
        "# Bidirectional LSTM layer replaced with Attention layer\n",
        "lstm_layer = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.3))(embedding_layer)\n",
        "attention = Attention()([lstm_layer, lstm_layer])  # Attention layer\n",
        "\n",
        "# 1D Convolutional layer\n",
        "conv1d_layer = Conv1D(64, kernel_size=3, activation='relu')(attention)\n",
        "\n",
        "# GlobalMaxPooling1D layer\n",
        "global_max_pooling_layer = GlobalMaxPooling1D()(conv1d_layer)\n",
        "\n",
        "# Dense layers\n",
        "dense_layer_1 = Dense(128, activation='relu')(global_max_pooling_layer)\n",
        "output_layer = Dense(1, activation='sigmoid')(dense_layer_1)\n",
        "\n",
        "# Model creation\n",
        "model = Model(inputs=input_layer, outputs=output_layer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:36:18.020073Z",
          "iopub.execute_input": "2024-01-27T12:36:18.020809Z",
          "iopub.status.idle": "2024-01-27T12:36:18.325899Z",
          "shell.execute_reply.started": "2024-01-27T12:36:18.02078Z",
          "shell.execute_reply": "2024-01-27T12:36:18.324936Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojjeuf1JPYkS",
        "outputId": "22b82249-4fdf-4cd0-eac1-c5acb0fae1f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:36:18.327353Z",
          "iopub.execute_input": "2024-01-27T12:36:18.32763Z",
          "iopub.status.idle": "2024-01-27T12:36:18.358681Z",
          "shell.execute_reply.started": "2024-01-27T12:36:18.327606Z",
          "shell.execute_reply": "2024-01-27T12:36:18.357885Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToCXUoujPYkS",
        "outputId": "58a69d47-6e94-44d7-a08d-ee3b46b4fed5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 200)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 200, 128)             1716249   ['input_1[0][0]']             \n",
            "                                                          6                                       \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 200, 256)             263168    ['embedding[0][0]']           \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " attention (Attention)       (None, 200, 256)             0         ['bidirectional[0][0]',       \n",
            "                                                                     'bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 198, 64)              49216     ['attention[0][0]']           \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 64)                   0         ['conv1d[0][0]']              \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  8320      ['global_max_pooling1d[0][0]']\n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    129       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17483329 (66.69 MB)\n",
            "Trainable params: 17483329 (66.69 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:36:18.637Z",
          "iopub.execute_input": "2024-01-27T12:36:18.637284Z",
          "iopub.status.idle": "2024-01-27T12:36:18.648301Z",
          "shell.execute_reply.started": "2024-01-27T12:36:18.63726Z",
          "shell.execute_reply": "2024-01-27T12:36:18.647562Z"
        },
        "trusted": true,
        "id": "tTfvUvF5PYkS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "history = model.fit(X_train_padded,y_train,batch_size=128,epochs=10,validation_data=(X_val_padded,y_val))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-27T12:36:20.651773Z",
          "iopub.execute_input": "2024-01-27T12:36:20.65217Z",
          "iopub.status.idle": "2024-01-27T13:01:15.320389Z",
          "shell.execute_reply.started": "2024-01-27T12:36:20.652143Z",
          "shell.execute_reply": "2024-01-27T13:01:15.319256Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh5zu0pBPYkS",
        "outputId": "c55adfbe-4b67-408b-f2db-53861200fc95"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "993/993 [==============================] - 1347s 1s/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5007\n",
            "Epoch 2/10\n",
            "993/993 [==============================] - 1281s 1s/step - loss: 0.6676 - accuracy: 0.5660 - val_loss: 0.6434 - val_accuracy: 0.6117\n",
            "Epoch 3/10\n",
            "993/993 [==============================] - 1284s 1s/step - loss: 0.5920 - accuracy: 0.6761 - val_loss: 0.6464 - val_accuracy: 0.6192\n",
            "Epoch 4/10\n",
            "993/993 [==============================] - 1283s 1s/step - loss: 0.4412 - accuracy: 0.7967 - val_loss: 0.7814 - val_accuracy: 0.5951\n",
            "Epoch 5/10\n",
            "993/993 [==============================] - 1272s 1s/step - loss: 0.2771 - accuracy: 0.8867 - val_loss: 0.9320 - val_accuracy: 0.6005\n",
            "Epoch 6/10\n",
            "993/993 [==============================] - 1252s 1s/step - loss: 0.1728 - accuracy: 0.9342 - val_loss: 1.2428 - val_accuracy: 0.5936\n",
            "Epoch 7/10\n",
            "993/993 [==============================] - 1259s 1s/step - loss: 0.1176 - accuracy: 0.9563 - val_loss: 1.4675 - val_accuracy: 0.5871\n",
            "Epoch 8/10\n",
            "993/993 [==============================] - 1240s 1s/step - loss: 0.0876 - accuracy: 0.9675 - val_loss: 1.8389 - val_accuracy: 0.5947\n",
            "Epoch 9/10\n",
            "993/993 [==============================] - 1219s 1s/step - loss: 0.0680 - accuracy: 0.9745 - val_loss: 1.8380 - val_accuracy: 0.5884\n",
            "Epoch 10/10\n",
            "993/993 [==============================] - 1236s 1s/step - loss: 0.0546 - accuracy: 0.9783 - val_loss: 2.3770 - val_accuracy: 0.5852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test_padded)\n",
        "y_pred_labels = np.where(predictions > 0.5, 1, 0)"
      ],
      "metadata": {
        "id": "7u69XgyonUex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Compute various evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "precision = precision_score(y_test, y_pred_labels)\n",
        "recall = recall_score(y_test, y_pred_labels)\n",
        "f1 = f1_score(y_test, y_pred_labels)\n",
        "\n",
        "# Generate a confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZSR9TyIz2tQ",
        "outputId": "ba0d1731-f3c7-476a-d3ac-7b3e3fef5bbd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5896767083027186\n",
            "Precision: 0.5865914000975678\n",
            "Recall: 0.6164493921195254\n",
            "F1-score: 0.6011498767989143\n",
            "Confusion Matrix:\n",
            "[[7634 5932]\n",
            " [5237 8417]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"drive/MyDrive/bilstm_bias.keras\")"
      ],
      "metadata": {
        "id": "BRT3GAoiti4g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"drive/MyDrive/bilstm_bias_weights.h5\")\n"
      ],
      "metadata": {
        "id": "CQ9HE8JTJgx4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BiLSTM with both unbiased and biased sentences included, training limited to 130,000 sentences."
      ],
      "metadata": {
        "id": "wtG-R6ZHnuBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store labeled data\n",
        "labeled_train = []\n",
        "\n",
        "# Iterate through each tuple in 'data'\n",
        "for row in train_pairs.text_pairs_dict:\n",
        "    # Randomly select either src_raw or tgt_raw\n",
        "    row = eval(row)\n",
        "\n",
        "    # Append the tuple containing the selected text and its label to 'labeled_data'\n",
        "    labeled_train.append((row[0], 0))\n",
        "    labeled_train.append((row[1], 1))\n",
        "\n",
        "# Shuffle the labeled_data\n",
        "random.shuffle(labeled_train)\n",
        "\n",
        "# Convert to DataFrame\n",
        "data_train = labeled_train\n",
        "df_train = pd.DataFrame(data_train, columns=['text', 'label'])\n",
        "y_train = df_train['label']"
      ],
      "metadata": {
        "id": "9s3G5CcEmkLc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train[:130000]\n",
        "y_train = df_train['label']"
      ],
      "metadata": {
        "id": "V-irW896ov-b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store labeled data\n",
        "labeled_val = []\n",
        "\n",
        "# Iterate through each tuple in 'data'\n",
        "for row in valid_pairs.text_pairs_dict:\n",
        "    # Randomly select either src_raw or tgt_raw\n",
        "    row = eval(row)\n",
        "\n",
        "    # Append the tuple containing the selected text and its label to 'labeled_data'\n",
        "    labeled_val.append((row[0], 0))\n",
        "    labeled_val.append((row[1], 1))\n",
        "\n",
        "# Shuffle the labeled_data\n",
        "random.shuffle(labeled_val)\n",
        "\n",
        "# Convert to DataFrame\n",
        "data_val = labeled_val\n",
        "df_val = pd.DataFrame(data_val, columns=['text', 'label'])\n",
        "y_val = df_val['label']"
      ],
      "metadata": {
        "id": "SPtk0Vr8mpSS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store labeled data\n",
        "labeled_test = []\n",
        "\n",
        "# Iterate through each tuple in 'data'\n",
        "for row in test_pairs.text_pairs_dict:\n",
        "    # Randomly select either src_raw or tgt_raw\n",
        "    row = eval(row)\n",
        "\n",
        "    # Append the tuple containing the selected text and its label to 'labeled_data'\n",
        "    labeled_test.append((row[0], 0))\n",
        "    labeled_test.append((row[1], 1))\n",
        "\n",
        "# Shuffle the labeled_data\n",
        "random.shuffle(labeled_test)\n",
        "\n",
        "# Convert to DataFrame\n",
        "data_test = labeled_test\n",
        "df_test = pd.DataFrame(data_test, columns=['text', 'label'])\n",
        "y_test = df_test['label']"
      ],
      "metadata": {
        "id": "DSjy8fU9nLdL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.to_csv(\"drive/MyDrive/df_train.csv\")\n",
        "df_val.to_csv(\"drive/MyDrive/df_val.csv\")\n",
        "df_test.to_csv(\"drive/MyDrive/df_test.csv\")"
      ],
      "metadata": {
        "id": "V_-yU4a1B08p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_cleaned = df_train['text'].apply(clean)\n",
        "x_val_cleaned = df_val['text'].apply(clean)\n",
        "x_test_cleaned = df_test['text'].apply(clean)"
      ],
      "metadata": {
        "id": "ktbNavItneVg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train_cleaned)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(x_train_cleaned)\n",
        "X_val_sequences = tokenizer.texts_to_sequences(x_val_cleaned)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(x_test_cleaned)"
      ],
      "metadata": {
        "id": "cUeR6gJYniCs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index)\n",
        "print(total_words) #same as length of vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uj5LGeQxnkCd",
        "outputId": "34b52134-a0fe-444d-c68c-45aaff3cf53f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_len=len(tokenizer.index_word)+1"
      ],
      "metadata": {
        "id": "Z3XIb3-jnnEr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the length of the maximum sequence in the dataset\n",
        "max_length = max([len(w) for w in X_train_sequences])\n",
        "print(max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVdgMOOVnqCQ",
        "outputId": "b552a1b9-4f35-495c-b065-29ff70e9048c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding the sequences\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=200, padding='post', truncating='post')\n",
        "X_val_padded = pad_sequences(X_val_sequences, maxlen=200, padding='post', truncating='post')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=200, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "kEyjlEBgnrjw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input layer\n",
        "input_layer = Input(shape=(200,))  # Specify max_len as the maximum sequence length\n",
        "\n",
        "# Embedding layer\n",
        "embedding_layer = Embedding(emb_len, 128)(input_layer)\n",
        "\n",
        "# Bidirectional LSTM layer replaced with Attention layer\n",
        "lstm_layer = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.3))(embedding_layer)\n",
        "attention = Attention()([lstm_layer, lstm_layer])  # Attention layer\n",
        "\n",
        "# 1D Convolutional layer\n",
        "conv1d_layer = Conv1D(64, kernel_size=3, activation='relu')(attention)\n",
        "\n",
        "# GlobalMaxPooling1D layer\n",
        "global_max_pooling_layer = GlobalMaxPooling1D()(conv1d_layer)\n",
        "\n",
        "# Dense layers\n",
        "dense_layer_1 = Dense(128, activation='relu')(global_max_pooling_layer)\n",
        "output_layer = Dense(1, activation='sigmoid')(dense_layer_1)\n",
        "\n",
        "# Model creation\n",
        "model = Model(inputs=input_layer, outputs=output_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VaXo8AXntyR",
        "outputId": "072acc9d-3d0e-4fac-8995-766656d7dc49"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RwMiZxInw3W",
        "outputId": "773db199-b0eb-475d-c1cf-12c41d0e7be7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 200)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 200, 128)             1782195   ['input_1[0][0]']             \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 200, 256)             263168    ['embedding[0][0]']           \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " attention (Attention)       (None, 200, 256)             0         ['bidirectional[0][0]',       \n",
            "                                                                     'bidirectional[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 198, 64)              49216     ['attention[0][0]']           \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 64)                   0         ['conv1d[0][0]']              \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  8320      ['global_max_pooling1d[0][0]']\n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    129       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 18142785 (69.21 MB)\n",
            "Trainable params: 18142785 (69.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CqI2jja7nzav"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "history = model.fit(X_train_padded,y_train,batch_size=128,epochs=10,validation_data=(X_val_padded,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF-q2fKxn08m",
        "outputId": "eff9ea66-577e-4946-db06-5763596f9504"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1016/1016 [==============================] - 1403s 1s/step - loss: 0.6933 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1016/1016 [==============================] - 1386s 1s/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1016/1016 [==============================] - 1412s 1s/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5027\n",
            "Epoch 4/10\n",
            "1016/1016 [==============================] - 1356s 1s/step - loss: 0.6594 - accuracy: 0.5865 - val_loss: 0.6356 - val_accuracy: 0.6219\n",
            "Epoch 5/10\n",
            "1016/1016 [==============================] - 1378s 1s/step - loss: 0.6154 - accuracy: 0.6422 - val_loss: 0.6256 - val_accuracy: 0.6341\n",
            "Epoch 6/10\n",
            "1016/1016 [==============================] - 1377s 1s/step - loss: 0.5532 - accuracy: 0.6955 - val_loss: 0.6483 - val_accuracy: 0.6294\n",
            "Epoch 7/10\n",
            "1016/1016 [==============================] - 1373s 1s/step - loss: 0.4750 - accuracy: 0.7541 - val_loss: 0.6953 - val_accuracy: 0.6205\n",
            "Epoch 8/10\n",
            "1016/1016 [==============================] - 1355s 1s/step - loss: 0.3951 - accuracy: 0.8032 - val_loss: 0.7509 - val_accuracy: 0.6149\n",
            "Epoch 9/10\n",
            "1016/1016 [==============================] - 1348s 1s/step - loss: 0.3275 - accuracy: 0.8394 - val_loss: 0.9352 - val_accuracy: 0.6099\n",
            "Epoch 10/10\n",
            "1016/1016 [==============================] - 1434s 1s/step - loss: 0.2764 - accuracy: 0.8630 - val_loss: 1.0416 - val_accuracy: 0.6073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Evaluate Model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkRgmTKNn3kq",
        "outputId": "d23aa5af-5632-4070-8115-a48d998e7fbf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1702/1702 [==============================] - 204s 120ms/step - loss: 1.0432 - accuracy: 0.6075\n",
            "Test Loss: 1.0432424545288086, Test Accuracy: 0.6074944734573364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "predictions = model.predict(X_test_padded)\n",
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7LnDVwyn5Wq",
        "outputId": "993ac190-5e53-47ff-e8d0-40802a67a5f8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1702/1702 [==============================] - 201s 118ms/step\n",
            "[[0.34324637]\n",
            " [0.4670872 ]\n",
            " [0.46466786]\n",
            " ...\n",
            " [0.7599771 ]\n",
            " [0.8916219 ]\n",
            " [0.6614792 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "threshold = 0.5\n",
        "binary_predictions = np.where(predictions >= threshold, 1, 0)\n",
        "confusion_matrix(y_test, binary_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsAQ6ooShX-q",
        "outputId": "3eb0de93-1f6e-4ad6-91aa-f900b8020daa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16044, 11176],\n",
              "       [10192, 17028]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_zeros = np.count_nonzero(binary_predictions == 0)\n",
        "print(num_zeros)\n",
        "num_ones = np.count_nonzero(binary_predictions == 1)\n",
        "print(num_ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bowgYWNTiKPm",
        "outputId": "a66615af-217b-41f8-8d8f-0c8fcc60f6de"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26236\n",
            "28204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"drive/MyDrive/bilstm_bias2.keras\")\n",
        "model.save_weights(\"drive/MyDrive/bilstm_bias_weights2.h5\")\n",
        "model.save(\"drive/MyDrive/bilstm_bias2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-SFTDP4n8Ax",
        "outputId": "6eb4d8a8-9a48-4a52-ead5-2092980757cf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}