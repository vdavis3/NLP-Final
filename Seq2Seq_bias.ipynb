{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGXolkzbupT8",
        "outputId": "69016462-0fae-40ca-ce40-5f39abff1be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.4/508.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade keras-nlp\n",
        "!pip install -q --upgrade keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "import keras\n",
        "from keras import ops\n",
        "import tensorflow as tf\n",
        "import tensorflow.data as tf_data\n",
        "from tensorflow_text.tools.wordpiece_vocab import (\n",
        "    bert_vocab_from_dataset as bert_vocab,\n",
        ")"
      ],
      "metadata": {
        "id": "9QUgsQo4uq4l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load files\n",
        "train_pairs = pd.read_csv('drive/MyDrive/train_pairs.csv')\n",
        "valid_pairs = pd.read_csv('drive/MyDrive/valid_pairs.csv')\n",
        "test_pairs = pd.read_csv('drive/MyDrive/test_pairs.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yBwKRsouu9A",
        "outputId": "4b0b0dba-c702-4817-e4ca-1c1711228005"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#modify from pairs used in t5 fine tuning\n",
        "prefix = 'translate biased to unbiased: '\n",
        "\n",
        "train_pairs = train_pairs.text_pairs_dict.apply(lambda x: tuple(eval(x).values())).apply(lambda x: (x[0][len(prefix):], x[1]))\n",
        "val_pairs = valid_pairs.text_pairs_dict.apply(lambda x: tuple(eval(x).values())).apply(lambda x: (x[0][len(prefix):], x[1]))\n",
        "test_pairs = test_pairs.text_pairs_dict.apply(lambda x: tuple(eval(x).values())).apply(lambda x: (x[0][len(prefix):], x[1]))"
      ],
      "metadata": {
        "id": "o5Lk2srMu22M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = 'drive/MyDrive/train_pairsS2S.csv'\n",
        "valid_file = 'drive/MyDrive/valid_pairsS2S.csv'\n",
        "test_file = 'drive/MyDrive/test_pairsS2S.csv'\n",
        "\n",
        "pd.DataFrame(train_pairs).to_csv(train_file)\n",
        "pd.DataFrame(val_pairs).to_csv(valid_file)\n",
        "pd.DataFrame(test_pairs).to_csv(test_file)"
      ],
      "metadata": {
        "id": "b5s8iIqHzrrn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(train_pairs)+len(val_pairs)+len(test_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTMRBnQEuyHK",
        "outputId": "02a8f9aa-46b1-4b54-a649-409858ecf777"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181473 total pairs\n",
            "127033 training pairs\n",
            "27220 validation pairs\n",
            "27220 test pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_word_piece(text_samples, vocab_size, reserved_tokens):\n",
        "    word_piece_ds = tf.data.Dataset.from_tensor_slices(text_samples)\n",
        "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
        "        word_piece_ds.batch(1000).prefetch(2),\n",
        "        vocabulary_size=vocab_size,\n",
        "        reserved_tokens=reserved_tokens,\n",
        "    )\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "vj_4IPyeu3T4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10  # This should be at least 10 for convergence\n",
        "MAX_SEQUENCE_LENGTH = 256\n",
        "\n",
        "#The size of our source and target language vocabularies\n",
        "ORG_VOCAB_SIZE = 15000\n",
        "MOD_VOCAB_SIZE = 15000\n",
        "\n",
        "#define some hyperparameter values for our transformers\n",
        "EMBED_DIM = 256\n",
        "INTERMEDIATE_DIM = 2048\n",
        "NUM_HEADS = 8"
      ],
      "metadata": {
        "id": "dfHm7ql7u9H3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
        "\n",
        "# Biased Examples (Original)\n",
        "org_samples = [text_pair[0] for text_pair in train_pairs]\n",
        "org_vocab = train_word_piece(org_samples, ORG_VOCAB_SIZE, reserved_tokens)\n",
        "\n",
        "# Unbiased Examples (Modified)\n",
        "mod_samples = [text_pair[1] for text_pair in train_pairs]\n",
        "mod_vocab = train_word_piece(mod_samples, MOD_VOCAB_SIZE, reserved_tokens)"
      ],
      "metadata": {
        "id": "ntRGxwzhvANz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Biased Tokens: \", org_vocab[1000:1020])\n",
        "print(\"Unbiased Tokens: \", mod_vocab[1000:1020])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2a1evxJvAiS",
        "outputId": "852f7bac-e886-4514-ab32-76d0bc92634b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Biased Tokens:  ['african', 'half', 'woman', 'announced', 'information', 'least', '##ts', 'numerous', 'reported', 'stated', 'founder', 'legendary', 'present', '##um', '19', 'production', 'russia', '21', 'eastern', 'association']\n",
            "Unbiased Tokens:  ['areas', 'street', 'medical', 'themselves', '##re', '28', 'once', 'half', 'natural', 'commonly', 'list', 'notable', 'arab', 'important', 'performance', 'project', 're', 'woman', 'continued', 'gay']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "org_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=org_vocab, lowercase=True\n",
        ")\n",
        "mod_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=mod_vocab, lowercase=True\n",
        ")"
      ],
      "metadata": {
        "id": "MtWU810lvEjx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "org_input_ex = train_pairs[0][0]\n",
        "org_tokens_ex = org_tokenizer.tokenize(org_input_ex)\n",
        "print(\"Biased sentence: \", org_input_ex)\n",
        "print(\"Tokens: \", org_tokens_ex)\n",
        "print(\n",
        "    \"Recovered text after detokenizing: \",\n",
        "    org_tokenizer.detokenize(org_tokens_ex),\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "mod_input_ex = train_pairs[0][1]\n",
        "mod_tokens_ex = mod_tokenizer.tokenize(mod_input_ex)\n",
        "print(\"Unbiased sentence: \", mod_input_ex)\n",
        "print(\"Tokens: \", mod_tokens_ex)\n",
        "print(\n",
        "    \"Recovered text after detokenizing: \",\n",
        "    mod_tokenizer.detokenize(mod_tokens_ex),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYwj8PJ5vH-r",
        "outputId": "92809a38-25ce-4f2b-a926-875f66bba019"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Biased sentence:  this loris is a small, slender , cute looking primate with big forward facing eyes.\n",
            "Tokens:  tf.Tensor(\n",
            "[  318    50 10019   304   297    39   622    14    57  8957  1810    14\n",
            "  8854  2743    54  5896   997   305  1139  2405  4587  3087    16], shape=(23,), dtype=int32)\n",
            "Recovered text after detokenizing:  tf.Tensor(b'this loris is a small , slender , cute looking primate with big forward facing eyes .', shape=(), dtype=string)\n",
            "\n",
            "Unbiased sentence:  this loris is a small, slender primate with big forward facing eyes.\n",
            "Tokens:  tf.Tensor(\n",
            "[ 322   50 9088  307  300   39  682   14   57 8918 1560   54 6348  983\n",
            "  308 1247 2529 4642 3096   16], shape=(20,), dtype=int32)\n",
            "Recovered text after detokenizing:  tf.Tensor(b'this loris is a small , slender primate with big forward facing eyes .', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_batch(org, mod):\n",
        "    batch_size = tf.shape(mod)[0]\n",
        "\n",
        "    org = org_tokenizer(org)\n",
        "    mod = mod_tokenizer(mod)\n",
        "\n",
        "    # Pad `biased` to `MAX_SEQUENCE_LENGTH`.\n",
        "    org_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
        "        sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "        pad_value=org_tokenizer.token_to_id(\"[PAD]\"),\n",
        "    )\n",
        "    org = org_start_end_packer(org)\n",
        "\n",
        "    # Add special tokens (`\"[START]\"` and `\"[END]\"`) to `unbiased` and pad it as well.\n",
        "    mod_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
        "        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n",
        "        start_value=mod_tokenizer.token_to_id(\"[START]\"),\n",
        "        end_value=mod_tokenizer.token_to_id(\"[END]\"),\n",
        "        pad_value=mod_tokenizer.token_to_id(\"[PAD]\"),\n",
        "    )\n",
        "    mod = mod_start_end_packer(mod)\n",
        "\n",
        "    return (\n",
        "        {\n",
        "            \"encoder_inputs\": org,\n",
        "            \"decoder_inputs\": mod[:, :-1],\n",
        "        },\n",
        "        mod[:, 1:],\n",
        "    )\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    org_texts, mod_texts = zip(*pairs)\n",
        "    org_texts = list(org_texts)\n",
        "    mod_texts = list(mod_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((org_texts, mod_texts))\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n"
      ],
      "metadata": {
        "id": "z7ZaXHLJvKir"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make the training data\n",
        "train_ds = make_dataset(train_pairs)\n",
        "\n",
        "#make the validation data\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "metadata": {
        "id": "zMqkM8TBvMAY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dEqOGr2vNdp",
        "outputId": "f47fb29f-7b59-46e7-a68b-669abc1af4c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 256)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 256)\n",
            "targets.shape: (64, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=ORG_VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    #mask_zero=True,\n",
        ")(encoder_inputs)\n",
        "\n",
        "encoder_outputs = keras_nlp.layers.TransformerEncoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(inputs=x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)"
      ],
      "metadata": {
        "id": "krQw1c-cvPjh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, EMBED_DIM), name=\"decoder_state_inputs\")\n",
        "\n",
        "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=MOD_VOCAB_SIZE,\n",
        "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    #mask_zero=True,\n",
        ")(decoder_inputs)\n",
        "\n",
        "x = keras_nlp.layers.TransformerDecoder(\n",
        "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
        ")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "decoder_outputs = keras.layers.Dense(MOD_VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "decoder = keras.Model(\n",
        "    [\n",
        "        decoder_inputs,\n",
        "        encoded_seq_inputs,\n",
        "    ],\n",
        "    decoder_outputs,\n",
        ")\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])"
      ],
      "metadata": {
        "id": "e0kyr1qmvQBH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#connect the encoder and decoder together in sequence\n",
        "seq2seq = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs],\n",
        "    decoder_outputs,\n",
        "    name=\"s2sTransformer\",\n",
        ")"
      ],
      "metadata": {
        "id": "gG31MxncvSS5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "sLBzCOyZvTf8",
        "outputId": "422ae501-4229-4984-f831-a79df0d1a6e4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"s2sTransformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"s2sTransformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ token_and_position_embed… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,905,536\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbeddi…\u001b[0m │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m1,315,072\u001b[0m │ token_and_position_em… │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_3 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15000\u001b[0m)    │      \u001b[38;5;34m9,339,288\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                           │                        │                │ transformer_encoder[\u001b[38;5;34m0\u001b[0m… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ token_and_position_embed… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,905,536</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbeddi…</span> │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,315,072</span> │ token_and_position_em… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ functional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,339,288</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                           │                        │                │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,559,896\u001b[0m (55.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,559,896</span> (55.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,559,896\u001b[0m (55.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,559,896</span> (55.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Rpkgchi1vWt5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq.fit(train_ds, epochs=EPOCHS, validation_data=val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lp4VI3cvZR_",
        "outputId": "9da9134f-60fd-4d5a-f7a6-8b4eae0e7390"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m746s\u001b[0m 354ms/step - accuracy: 0.8682 - loss: 1.1801 - val_accuracy: 0.8802 - val_loss: 0.8656\n",
            "Epoch 2/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m654s\u001b[0m 330ms/step - accuracy: 0.8848 - loss: 0.8441 - val_accuracy: 0.9151 - val_loss: 0.6250\n",
            "Epoch 3/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 329ms/step - accuracy: 0.9197 - loss: 0.5978 - val_accuracy: 0.9347 - val_loss: 0.4621\n",
            "Epoch 4/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m681s\u001b[0m 329ms/step - accuracy: 0.9350 - loss: 0.4642 - val_accuracy: 0.9414 - val_loss: 0.3904\n",
            "Epoch 5/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m652s\u001b[0m 328ms/step - accuracy: 0.9426 - loss: 0.3933 - val_accuracy: 0.9441 - val_loss: 0.3575\n",
            "Epoch 6/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m649s\u001b[0m 327ms/step - accuracy: 0.9469 - loss: 0.3519 - val_accuracy: 0.9462 - val_loss: 0.3374\n",
            "Epoch 7/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 326ms/step - accuracy: 0.9496 - loss: 0.3252 - val_accuracy: 0.9485 - val_loss: 0.3212\n",
            "Epoch 8/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m648s\u001b[0m 327ms/step - accuracy: 0.9517 - loss: 0.3056 - val_accuracy: 0.9496 - val_loss: 0.3129\n",
            "Epoch 9/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m651s\u001b[0m 328ms/step - accuracy: 0.9536 - loss: 0.2892 - val_accuracy: 0.9503 - val_loss: 0.3064\n",
            "Epoch 10/10\n",
            "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m650s\u001b[0m 327ms/step - accuracy: 0.9553 - loss: 0.2753 - val_accuracy: 0.9507 - val_loss: 0.3033\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ab8bf016290>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq.load_weights(\"drive/MyDrive/seq2seq.weights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs2yMdEVEUsb",
        "outputId": "4c01dc8d-f2ae-4d6c-a081-298366c1f94f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  trackable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq2seq.save(\"drive/MyDrive/seq2seq.keras\")\n",
        "seq2seq.save_weights(\"drive/MyDrive/seq2seq.weights.h5\")\n"
      ],
      "metadata": {
        "id": "LHjCdlY6vbOl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequences(input_sentences):\n",
        "    batch_size = tf.shape(input_sentences)[0]\n",
        "\n",
        "    # Tokenize the encoder input.\n",
        "    encoder_input_tokens = org_tokenizer(input_sentences).to_tensor(\n",
        "        shape=(None, MAX_SEQUENCE_LENGTH)\n",
        "    )\n",
        "\n",
        "    # Define a function that outputs the next token's probability given the\n",
        "    # input sequence.\n",
        "    def next(prompt, cache, index):\n",
        "        logits = seq2seq([encoder_input_tokens, prompt])[:, index - 1, :]\n",
        "        # Ignore hidden states for now; only needed for contrastive search.\n",
        "        hidden_states = None\n",
        "        return logits, hidden_states, cache\n",
        "\n",
        "    # Build a prompt of length 128 with a start token and padding tokens.\n",
        "    length = 128\n",
        "    start = tf.fill((batch_size, 1), mod_tokenizer.token_to_id(\"[START]\"))\n",
        "    pad = tf.fill((batch_size, length - 1), mod_tokenizer.token_to_id(\"[PAD]\"))\n",
        "    prompt = tf.concat((start, pad), axis=-1)\n",
        "\n",
        "    generated_tokens = keras_nlp.samplers.GreedySampler()(\n",
        "        next,\n",
        "        prompt,\n",
        "        #end_token_id=mod_tokenizer.token_to_id(\"[END]\"),\n",
        "        index=1,  # Start sampling after start token.\n",
        "    )\n",
        "    generated_sentences = mod_tokenizer.detokenize(generated_tokens)\n",
        "    return generated_sentences\n",
        "\n",
        "examples = ['the player must not make any move that would place his king in check.',\n",
        "            \"the lyrics are about mankind 's perceived idea of hell.\",\n",
        "            'marriage is a holy union of individuals.']\n",
        "for input_sentence in examples:\n",
        "    translated = decode_sequences(tf.constant([input_sentence]))\n",
        "    translated = translated.numpy()[0].decode(\"utf-8\")\n",
        "    translated = (\n",
        "        translated.replace(\"[PAD]\", \"\")\n",
        "        .replace(\"[START]\", \"\")\n",
        "        .replace(\"[END]\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    print(\"Input: \" + input_sentence)\n",
        "    print(\"Output: \" + translated)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dc0uH8GEbMq",
        "outputId": "b0e818eb-e975-48ce-befe-4d98244449cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: the player must not make any move that would place his king in check.\n",
            "Output: the player must not make any move that would place in his .\n",
            "\n",
            "Input: the lyrics are about mankind 's perceived idea of hell.\n",
            "Output: the lyrics are about humankind ' s perceived idea of hell .\n",
            "\n",
            "Input: marriage is a holy union of individuals.\n",
            "Output: marriage is a holy union of individuals .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example test data\n",
        "test_source_sequences = test_pairs.apply(lambda x: x[0])  # List of source sequences\n",
        "test_target_sequences = test_pairs.apply(lambda x: x[1])   # List of target sequences"
      ],
      "metadata": {
        "id": "1bMxkCmIVve3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_source_sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1KebC-Z_WwW5",
        "outputId": "494fad29-7e98-4161-89e6-83966d2e45d6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'he devoted his enormous energies to the destruction of what he considered the slave power, that is the conspiracy he saw of slave owners to seize control of the federal government and block the progress of liberty .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-bCV8dtW7NQ",
        "outputId": "20f0a246-60dc-42ce-b7b8-9d8f1959cd37"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_sequences3 = []\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 1000\n",
        "\n",
        "# Define the start index\n",
        "start_index = 8500\n",
        "\n",
        "# Divide source sequences into batches\n",
        "num_batches = ((len(test_source_sequences) - start_index) + batch_size - 1) // batch_size\n",
        "\n",
        "# Process each batch\n",
        "for i in range(num_batches):\n",
        "    start_idx = start_index + (i * batch_size)\n",
        "    end_idx = min(start_index + ((i + 1) * batch_size), len(test_source_sequences))\n",
        "    batch_sequences = test_source_sequences[start_idx:end_idx]\n",
        "\n",
        "    # Generate predictions for the current batch\n",
        "    batch_predictions = []\n",
        "    for source_sequence in batch_sequences:\n",
        "        # Generate prediction for source sequence using the loaded model\n",
        "        predicted_sequence = decode_sequences(tf.constant([source_sequence]))\n",
        "        predicted_sequence = predicted_sequence.numpy()[0].decode(\"utf-8\")\n",
        "        predicted_sequence = (\n",
        "            predicted_sequence.replace(\"[PAD]\", \"\")\n",
        "            .replace(\"[START]\", \"\")\n",
        "            .replace(\"[END]\", \"\")\n",
        "            .strip()\n",
        "        )\n",
        "        batch_predictions.append(predicted_sequence)\n",
        "\n",
        "    # Extend the list of predicted sequences with the batch predictions\n",
        "    predicted_sequences3.extend(batch_predictions)\n"
      ],
      "metadata": {
        "id": "WhFL14VzxsV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Define the function for processing a batch of sequences\n",
        "def process_batch(batch_sequences):\n",
        "    batch_predictions = []\n",
        "    for source_sequence in batch_sequences:\n",
        "        # Generate prediction for source sequence using the loaded model\n",
        "        predicted_sequence = decode_sequences(tf.constant([source_sequence]))\n",
        "        predicted_sequence = predicted_sequence.numpy()[0].decode(\"utf-8\")\n",
        "        predicted_sequence = (\n",
        "            predicted_sequence.replace(\"[PAD]\", \"\")\n",
        "            .replace(\"[START]\", \"\")\n",
        "            .replace(\"[END]\", \"\")\n",
        "            .strip()\n",
        "        )\n",
        "        batch_predictions.append(predicted_sequence)\n",
        "    return batch_predictions\n",
        "\n",
        "# Define batch size and start index\n",
        "batch_size = 1000\n",
        "start_index = 10500\n",
        "\n",
        "# Divide source sequences into batches\n",
        "num_batches = ((len(test_source_sequences) - start_index) + batch_size - 1) // batch_size\n",
        "\n",
        "# Create a multiprocessing pool\n",
        "pool = multiprocessing.Pool()\n",
        "\n",
        "# Process each batch in parallel\n",
        "results = []\n",
        "for i in range(num_batches):\n",
        "    start_idx = start_index + (i * batch_size)\n",
        "    end_idx = min(start_index + ((i + 1) * batch_size), len(test_source_sequences))\n",
        "    batch_sequences = test_source_sequences[start_idx:end_idx]\n",
        "    results.append(pool.apply_async(process_batch, args=(batch_sequences,)))\n",
        "\n",
        "# Get the results from all processes\n",
        "predicted_sequences4 = []\n",
        "for result in results:\n",
        "    predicted_sequences4.extend(result.get())\n",
        "\n",
        "# Close the pool\n",
        "pool.close()\n",
        "pool.join()\n"
      ],
      "metadata": {
        "id": "T31gYcRu6SYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(predicted_sequences3).to_csv(\"drive/MyDrive/test_seq2seq_sequences3.csv\")"
      ],
      "metadata": {
        "id": "7BmlEOTfCNGR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate metrics\n",
        "\n",
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from rouge import Rouge\n",
        "from sklearn.metrics import accuracy_score\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "\n",
        "\n",
        "# Compute BLEU score\n",
        "bleu_scores = [sentence_bleu([target_sequence], predicted_sequence) for target_sequence, predicted_sequence in zip(test_target_sequences, predicted_sequences)]\n",
        "average_bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
        "overall_bleu_score = corpus_bleu([[target_sequence] for target_sequence in test_target_sequences], predicted_sequences)\n",
        "\n",
        "# Compute ROUGE score\n",
        "rouge = Rouge()\n",
        "rouge_scores = rouge.get_scores([predicted_sequence for predicted_sequence in predicted_sequences], [target_sequence for target_sequence in test_target_sequences], avg=True)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(test_target_sequences, predicted_sequences)\n",
        "\n",
        "# Compute Similar Sequence Matcher score\n",
        "def similar(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "similarity_score = similar(test_target_sequences, predicted_sequences)\n",
        "\n",
        "# Print or store the evaluation metrics\n",
        "print(\"BLEU Score (Average):\", average_bleu_score)\n",
        "print(\"BLEU Score (Overall):\", overall_bleu_score)\n",
        "print(\"ROUGE Score (Avg):\", rouge_scores)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Similarity:\", similarity_score)"
      ],
      "metadata": {
        "id": "CI_OBvleVTAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}